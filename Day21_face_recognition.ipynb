{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Face Recognition with OpenCV\n",
        "\n",
        "Source: [Datacamp tutorial on face detection](https://www.datacamp.com/tutorial/face-detection-python-opencv)"
      ],
      "metadata": {
        "id": "8iSqn3I1k_E9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is OpenCV ?**\n",
        "\n",
        "This is a computer vision library. It was created by Intel in 1999 and was later made open-source and released to the public.\n",
        "Since the human faces are so diverse, face detection models are trained on large amounts of input data for accurate detection. The trainig dataset must be diverse.\n",
        "\n",
        "**Haar Cascade Classifiers**\n",
        "\n",
        "This method was first introduced in the paper Rapid Object Detection Using a Boosted Cascade of Simple Features, written by Paul Viola and Michael Jones."
      ],
      "metadata": {
        "id": "DkG21pPpoc8g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install opencv-python\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "2CeXhmJ3ntKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the image.\n",
        "# Returns the image in the form of a Numpy array\n",
        "imagePath = '/content/test_image_family.jpg'\n",
        "img = cv2.imread(imagePath)"
      ],
      "metadata": {
        "id": "0qKrjtzfqnPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's look at the dimensions of the image\n",
        "img.shape"
      ],
      "metadata": {
        "id": "7cWMPzOcqqE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a 3-dimensional array. They represent the height, width and channels respectively. Since this a color image, there are 3 channels- RGB (Red, green and Blue)\n",
        "\n",
        "The OpenCV library uses the opposite layout- BGR (Blue, Green and Red)"
      ],
      "metadata": {
        "id": "B5n-68k7q1dn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the image to Grayscale\n",
        "gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "gray_image.shape"
      ],
      "metadata": {
        "id": "3-Qe-aXeq0g5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the image no longer has 3 channels, there are only two values in the array."
      ],
      "metadata": {
        "id": "8QooIhg1rj89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained Haar Cascade Classifier\n",
        "face_classifier = cv2.CascadeClassifier(\n",
        "    cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\"\n",
        ")"
      ],
      "metadata": {
        "id": "y5m1QILCru4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Performing the Face Detection\n",
        "face = face_classifier.detectMultiScale(\n",
        "    gray_image, scaleFactor = 1.1, minNeighbors = 20 , minSize=(40,40)\n",
        ")"
      ],
      "metadata": {
        "id": "01kYmU9gsQYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The detectMultiScale() method is used to identify faces of different sizes in the Input Image.\n",
        "- scaleFactor: Scales down the size of the input image to make it easier for the algorithm to detect larger faces. We have specified scale factor of 1.1, indicating that we want to reduce the image size by 10%.\n",
        "\n",
        "- minNeighbors:\n",
        "The cascade classifier applies a sliding window through the image to detect faces in it. You can think of these windows as rectangles. Initially, the classifier will capture a large number of false positives. These are eliminated using the minNeighbors parameter, which specifies the number of neighboring rectangles that need to be identified for an object to be considered a valid detection. To summarize, passing a small value like 0 or 1 to this parameter would result in a high number of false positives, whereas a large number could lead to losing out on many true positives.The trick here is to find a tradeoff that allows us to eliminate false positives while also accurately identifying true positives.\n",
        "\n",
        "- minSize: This sets the minimum size of the object to be detected. The model will ignore faces that are smaller than the minimum size specified.\n"
      ],
      "metadata": {
        "id": "vhNtRt-Qs0DZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drawing the bounding boxes\n",
        "for (x, y, w, h) in face:\n",
        "    cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 4)\n",
        "\n",
        "# Displaying the Image\n",
        "# we first need to convert the image from the BGR format to RGB:\n",
        "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.imshow(img_rgb)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5t19fgMHt3jE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
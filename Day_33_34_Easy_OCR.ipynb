{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Easy OCR\n",
        "\n",
        "Ready-to-use OCR with 80+ supported languages and all popular writing scripts including: Latin, Chinese, Arabic, Devanagari, Cyrillic, etc.\n",
        "\n",
        "[API Documentation](https://www.jaided.ai/easyocr/documentation/)\n",
        "\n",
        "Live Demo: [Link on Hugging Face](https://huggingface.co/spaces/tomofi/EasyOCR)\n",
        "\n",
        "![image](https://raw.githubusercontent.com/JaidedAI/EasyOCR/master/examples/example.png)\n",
        "\n"
      ],
      "metadata": {
        "id": "Z7DMuT4wb1LL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Libraries"
      ],
      "metadata": {
        "id": "ZQksoqemfTpw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install easyocr\n",
        "import easyocr\n",
        "from IPython.display import Image"
      ],
      "metadata": {
        "id": "Q8z7zidietPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Image"
      ],
      "metadata": {
        "id": "r2vapV4-fWG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Image('/content/french_pic.jpg')"
      ],
      "metadata": {
        "id": "AZ5u8NWPekwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deriving Results"
      ],
      "metadata": {
        "id": "vtUNSQHXfazC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reader = easyocr.Reader(['fr','en']) # this needs to run only once to load the model into memory"
      ],
      "metadata": {
        "id": "tm4HXhfPcxHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = reader.readtext('/content/french_pic.jpg')"
      ],
      "metadata": {
        "id": "nfoqlPiCdT5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "id": "Lnh-CYf5eiZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output is in a list format, each item represents a bounding box, the text detected and confident level, respectively."
      ],
      "metadata": {
        "id": "QjY_DhYhffMD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To extract only the text\n",
        "reader.readtext('/content/french_pic.jpg', detail = 0)"
      ],
      "metadata": {
        "id": "QXAtmfDmgnwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now we can try to train our own models\n",
        "[Link to Documentation](https://github.com/JaidedAI/EasyOCR/blob/master/custom_model.md)\n",
        "\n"
      ],
      "metadata": {
        "id": "ax7UCBYHhvw9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class BidirectionalLSTM(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(BidirectionalLSTM, self).__init__()\n",
        "        self.rnn = nn.LSTM(input_size, hidden_size, bidirectional=True, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_size * 2, output_size)\n",
        "\n",
        "    def forward(self, input):\n",
        "        \"\"\"\n",
        "        input : visual feature [batch_size x T x input_size]\n",
        "        output : contextual feature [batch_size x T x output_size]\n",
        "        \"\"\"\n",
        "        try: # multi gpu needs this\n",
        "            self.rnn.flatten_parameters()\n",
        "        except: # quantization doesn't work with this\n",
        "            pass\n",
        "        recurrent, _ = self.rnn(input)  # batch_size x T x input_size -> batch_size x T x (2*hidden_size)\n",
        "        output = self.linear(recurrent)  # batch_size x T x output_size\n",
        "        return output\n",
        "\n",
        "class VGG_FeatureExtractor(nn.Module):\n",
        "\n",
        "    def __init__(self, input_channel, output_channel=256):\n",
        "        super(VGG_FeatureExtractor, self).__init__()\n",
        "        self.output_channel = [int(output_channel / 8), int(output_channel / 4),\n",
        "                               int(output_channel / 2), output_channel]\n",
        "        self.ConvNet = nn.Sequential(\n",
        "            nn.Conv2d(input_channel, self.output_channel[0], 3, 1, 1), nn.ReLU(True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(self.output_channel[0], self.output_channel[1], 3, 1, 1), nn.ReLU(True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(self.output_channel[1], self.output_channel[2], 3, 1, 1), nn.ReLU(True),\n",
        "            nn.Conv2d(self.output_channel[2], self.output_channel[2], 3, 1, 1), nn.ReLU(True),\n",
        "            nn.MaxPool2d((2, 1), (2, 1)),\n",
        "            nn.Conv2d(self.output_channel[2], self.output_channel[3], 3, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(self.output_channel[3]), nn.ReLU(True),\n",
        "            nn.Conv2d(self.output_channel[3], self.output_channel[3], 3, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(self.output_channel[3]), nn.ReLU(True),\n",
        "            nn.MaxPool2d((2, 1), (2, 1)),\n",
        "            nn.Conv2d(self.output_channel[3], self.output_channel[3], 2, 1, 0), nn.ReLU(True))\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.ConvNet(input)\n",
        "\n",
        "class Model(nn.Module):\n",
        "\n",
        "    def __init__(self, input_channel, output_channel, hidden_size, num_class):\n",
        "        super(Model, self).__init__()\n",
        "        \"\"\" FeatureExtraction \"\"\"\n",
        "        self.FeatureExtraction = VGG_FeatureExtractor(input_channel, output_channel)\n",
        "        self.FeatureExtraction_output = output_channel\n",
        "        self.AdaptiveAvgPool = nn.AdaptiveAvgPool2d((None, 1))\n",
        "\n",
        "        \"\"\" Sequence modeling\"\"\"\n",
        "        self.SequenceModeling = nn.Sequential(\n",
        "            BidirectionalLSTM(self.FeatureExtraction_output, hidden_size, hidden_size),\n",
        "            BidirectionalLSTM(hidden_size, hidden_size, hidden_size))\n",
        "        self.SequenceModeling_output = hidden_size\n",
        "\n",
        "        \"\"\" Prediction \"\"\"\n",
        "        self.Prediction = nn.Linear(self.SequenceModeling_output, num_class)\n",
        "\n",
        "\n",
        "    def forward(self, input, text):\n",
        "        \"\"\" Feature extraction stage \"\"\"\n",
        "        visual_feature = self.FeatureExtraction(input)\n",
        "        visual_feature = self.AdaptiveAvgPool(visual_feature.permute(0, 3, 1, 2))\n",
        "        visual_feature = visual_feature.squeeze(3)\n",
        "\n",
        "        \"\"\" Sequence modeling stage \"\"\"\n",
        "        contextual_feature = self.SequenceModeling(visual_feature)\n",
        "\n",
        "        \"\"\" Prediction stage \"\"\"\n",
        "        prediction = self.Prediction(contextual_feature.contiguous())\n",
        "\n",
        "        return prediction\n"
      ],
      "metadata": {
        "id": "hL0BaZgeii09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "network_params:\n",
        "\n",
        "*  input_channel: 1\n",
        "*  output_channel: 256\n",
        "*  hidden_size: 256\n",
        "\n",
        "imgH: 64\n",
        "\n",
        "lang_list: 'en'\n",
        "\n",
        "character_list:\n",
        "\n",
        "- 0123456789!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ â‚¬ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
      ],
      "metadata": {
        "id": "qTkoNavpitC5"
      }
    }
  ]
}